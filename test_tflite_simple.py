#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∏–π —Ç–µ—Å—Ç TFLite –º–æ–¥–µ–ª—ñ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –¥–µ—Ç–µ–∫—Ü—ñ—ó
"""

import tensorflow as tf
import cv2 as cv
import numpy as np
import os

# –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
TFLITE_MODEL_PATH = "weights/YOLO/model_3_simple.tflite"
TEST_IMAGE_PATH = "data/sample_battle_1.mp4"  # –í—ñ–∑—å–º–µ–º–æ –ø–µ—Ä—à–∏–π –∫–∞–¥—Ä –∑ –≤—ñ–¥–µ–æ

def test_tflite_model():
    """–¢–µ—Å—Ç—É—î–º–æ TFLite –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º—É –∫–∞–¥—Ä—ñ"""
    print("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è TFLite –º–æ–¥–µ–ª—ñ...")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
    if not os.path.exists(TFLITE_MODEL_PATH):
        print(f"‚ùå TFLite –º–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: {TFLITE_MODEL_PATH}")
        return
    
    interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)
    interpreter.allocate_tensors()
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–µ—Ç–∞–ª—ñ —Ç–µ–Ω–∑–æ—Ä—ñ–≤
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"üìä –í—Ö—ñ–¥–Ω–∞ —Ñ–æ—Ä–º–∞: {input_details[0]['shape']}")
    print(f"üìä –í–∏—Ö—ñ–¥–Ω–∞ —Ñ–æ—Ä–º–∞: {output_details[0]['shape']}")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–µ—Å—Ç–æ–≤–∏–π –∫–∞–¥—Ä
    cap = cv.VideoCapture(TEST_IMAGE_PATH)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑—á–∏—Ç–∞—Ç–∏ –∫–∞–¥—Ä")
        return
    
    print(f"üì∏ –†–æ–∑–º—ñ—Ä –∫–∞–¥—Ä—É: {frame.shape}")
    
    # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥
    input_shape = input_details[0]['shape']
    model_height, model_width = input_shape[2], input_shape[3]
    
    # –ó–º—ñ–Ω—é—î–º–æ —Ä–æ–∑–º—ñ—Ä –∫–∞–¥—Ä—É
    resized = cv.resize(frame, (model_width, model_height))
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ BGR –≤ RGB
    rgb_frame = cv.cvtColor(resized, cv.COLOR_BGR2RGB)
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—ñ–∫—Å–µ–ª—ñ–≤ [0-255] -> [0-1]
    normalized = rgb_frame.astype(np.float32) / 255.0
    
    # –¢—Ä–∞–Ω—Å–ø–æ–Ω—É—î–º–æ –≤ NCHW: [H, W, C] -> [C, H, W] —ñ –¥–æ–¥–∞—î–º–æ batch dimension
    input_data = np.expand_dims(np.transpose(normalized, (2, 0, 1)), axis=0)
    
    print(f"üîß –§–æ—Ä–º–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {input_data.shape}")
    
    # –í–∏–∫–æ–Ω—É—î–º–æ —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    print(f"üîß –§–æ—Ä–º–∞ –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {output_data.shape}")
    print(f"üîß –ú—ñ–Ω/–º–∞–∫—Å –∑–Ω–∞—á–µ–Ω–Ω—è –≤–∏—Ö–æ–¥—É: {np.min(output_data):.6f} / {np.max(output_data):.6f}")
    
    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤–∏—Ö—ñ–¥
    predictions = output_data[0]  # [5, 8400]
    print(f"üîß –§–æ—Ä–º–∞ predictions: {predictions.shape}")
    
    # –¢—Ä–∞–Ω—Å–ø–æ–Ω—É—î–º–æ –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ: [5, 8400] -> [8400, 5]
    predictions = predictions.T
    
    # –†–∞—Ö—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ–π –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]
    for threshold in thresholds:
        count = np.sum(predictions[:, 4] > threshold)  # confidence –≤ 5-–º—É —Å—Ç–æ–≤–ø—Ü—ñ
        print(f"üìä –î–µ—Ç–µ–∫—Ü—ñ—ó –∑ confidence > {threshold}: {count}")
    
    # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø-10 –¥–µ—Ç–µ–∫—Ü—ñ–π
    top_indices = np.argsort(predictions[:, 4])[-10:][::-1]
    print("\nüîù –¢–æ–ø-10 –¥–µ—Ç–µ–∫—Ü—ñ–π:")
    for i, idx in enumerate(top_indices):
        x_center, y_center, width, height, confidence = predictions[idx]
        print(f"   {i+1}. Confidence: {confidence:.6f}, Center: ({x_center:.3f}, {y_center:.3f}), Size: {width:.3f}x{height:.3f}")
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    test_tflite_model()
